{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Models\n",
    "\n",
    "## This Juypter Notebook was created to easily load the models and set/change the directories to test the models, all in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lchris/.pyenv/versions/3.9.1/lib/python3.9/site-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.9.1` and `torch==1.8.1` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
      "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from database import Database\n",
    "from models.altered_xception import AlteredXception\n",
    "from models.faster_r_cnn import FasterRCNN\n",
    "from models.rmac_model import RMACModel\n",
    "from utils import grab_images_and_paths, grab_all_image_paths "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Models and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 17:06:10.069180: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/lchris/Desktop/Coding/schoolprojects/comp490/COMPS/models/rmac_model.py:120: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  b = (W - wl) / (l + Wd - 1)\n",
      "/Users/lchris/Desktop/Coding/schoolprojects/comp490/COMPS/models/rmac_model.py:125: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  b = (H-wl)/(l+Hd-1)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: if the RMAC model needs to get descriptions of many different square regions, it will take a long time to load/initialize (roughly a minute).\n",
    "ax_model = AlteredXception()\n",
    "rmac_model = RMACModel(ax_model.model.get_layer(\"conv2d_3\").output_shape[1:], 3)\n",
    "rcnn_model = FasterRCNN()\n",
    "models = [ax_model, rmac_model, rcnn_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dir is the directory where our \"database\" of test images/frames and query images should exist. \n",
    "test_dir = \"/Users/lchris/Desktop/Coding/schoolprojects/comp490/COMPS/eval/test_images/test_games\"\n",
    "frame_paths, frames = grab_images_and_paths(os.path.join(test_dir, \"frames\"))\n",
    "query_image_paths = grab_all_image_paths(os.path.join(test_dir, \"query_images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-tTaYmNB-IM',\n",
       " 'q_hZHqNnwAU',\n",
       " 'r3FaHBe1rPw',\n",
       " 'S7Nqx_pyEl0',\n",
       " 'cmh9FnLbE5s',\n",
       " 'huGVGe3Afng',\n",
       " 'kQnQrYmhXW8',\n",
       " '_lAtb14VGm8',\n",
       " '0J57bBrDDLc',\n",
       " '5X6SctBSd9A']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the YouTube video \"ground truth\" from the IDs we picked, stored in a .txt file\n",
    "ground_truth_ids = []\n",
    "ground_truth_file_path = os.path.join(test_dir, \"ground_truth.txt\")\n",
    "with open(ground_truth_file_path, \"r\") as ground_truth:\n",
    "    for line in ground_truth.readlines():\n",
    "        youtube_ground_truth_id = line.split(\"/\")[-1].split(\".\")[0]\n",
    "        ground_truth_ids.append(youtube_ground_truth_id)\n",
    "ground_truth_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models to query from the evaluation database\n",
    "database = Database(os.path.join(test_dir, \"predictions\"))\n",
    "for model in models:\n",
    "    model.database = database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<models.altered_xception.AlteredXception object at 0x1772be8b0>\n",
      "<models.rmac_model.RMACModel object at 0x177fb3b50>\n",
      "<models.faster_r_cnn.FasterRCNN object at 0x17804f160>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Gathering predictions for each of the frames in the dataset\n",
    "for model in models:\n",
    "    print(model)\n",
    "    if (isinstance(model, AlteredXception)) and len(database.prediction_image_paths) < len(frame_paths):\n",
    "        model_predictions = model.predict_images(frames)\n",
    "        database.store_predictions(model_predictions, frame_paths)\n",
    "    if (isinstance(model, RMACModel)) and len(database.rmac_prediction_image_paths) < len(frame_paths):\n",
    "        model_predictions = model.predict_images(frames)\n",
    "        database.store_rmac_predictions(model_predictions, frame_paths)\n",
    "    if (isinstance(model, FasterRCNN)) and len(database.object_predictions) < len(frame_paths):\n",
    "        model_predictions = model.predict_image_paths(frame_paths)\n",
    "        database.store_object_data(model_predictions, frame_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_predictions(predictions):\n",
    "    video_id_preds = []\n",
    "    for prediction in predictions:\n",
    "        image_path = prediction[0].split(\"/\")[-1] # We only want the last part of the path\n",
    "        video_id = image_path[0:11]\n",
    "        video_id_preds.append(video_id)\n",
    "    return video_id_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for query_image_path in query_image_paths:\n",
    "    results[query_image_path] = {}\n",
    "    for model in models:\n",
    "        model_name = type(model).__name__\n",
    "        curr_predictions = post_process_predictions(model.query_image(query_image_path)[0:len(ground_truth_ids)])\n",
    "        results[query_image_path][model_name] = curr_predictions\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = {}\n",
    "for query_image_path in query_image_paths:\n",
    "    curr_results = results[query_image_path]\n",
    "    matches[query_image_path] = {}\n",
    "    for model in results[query_image_path]:\n",
    "        num_matches = 0\n",
    "        for id in ground_truth_ids:\n",
    "            if id in results[query_image_path][model]:\n",
    "                num_matches += 1\n",
    "        matches[query_image_path][model] = num_matches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('3.9.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d832aa6a45f3eb7e7bad55fdbd58c33e34218938f08b2d0a8c371f719f367be4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

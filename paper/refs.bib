@techreport {Stanford2017,
   author = {Arthurs, N. and Birnbaum, S. and Gruver, N.},
   title = {Selecting Youtube Video Thumbnails via Convolutional Neural Networks},
   institution = {Stanford},
   url ={http://cs231n.stanford.edu/reports/2017/pdfs/710.pdf},
   year = {2017},
}
@techreport {Stanford2021,
   author = {Chen, Y. and Wang, Y. and Tan, R.},
   title = {Classifying YouTube Videos by Thumbnail},
   institution = {Stanford},
   url = {http://cs230.stanford.edu/projects_fall_2021/reports/103085886.pdf},
   year = {2021},
}
@techreport {Adrakatti2016,
    author = {Adrakatti, A. and Wodeyar, R. and Mulla, K.},
    title = {Search by Image: A Novel Approach to Content Based Image Retrieval System},
    url = {https://www.researchgate.net/publication/305683970_Search_by_Image_A_Novel_Approach_to_Content_Based_Image_Retrieval_System},
    year = {2016},
}
@article {PrasadClustering,
   author = {Sunit Prasad},
   title = {Different Types of Clustering Methods and Applications},
   url = {https://www.analytixlabs.co.in/blog/types-of-clustering-algorithms/#sub1},
}
@article {C3Clustering,
   author={C3AI},
   title={Clustering},
   url={https://c3.ai/glossary/data-science/clustering/},
   year={2018}
}
@techreport {Kavitha2020,
   author = {Kavitha, P. K. and Saraswathi, Vidhya P.},
   title = {Content based satellite image retrieval system using fuzzy clustering},
   url = {https://link.springer.com/article/10.1007/s12652-020-02064-1},
   year = {2020},
}
@techreport {Schwammle2010,
   author = {Schwammle, V. and Jensen O.},
   title = {A simple and fast method to determine the parameters for fuzzy c–means cluster analysis},
   url = {https://academic.oup.com/bioinformatics/article/26/22/2841/227572},
   year = {2010},
}
@techreport {Moore2018,
   author = {Moore D. and Mamrosh J.},
   title = {Using Google Reverse Image Search to Decipher Biological Images},
   url = {https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/0471142727.mb1913s111},
   year = {2018},
}
@article{Mittal2021,
	title = {A comprehensive survey of image segmentation: clustering methods, performance parameters, and benchmark datasets},
	issn = {1380-7501, 1573-7721},
	shorttitle = {A comprehensive survey of image segmentation},
	url = {http://link.springer.com/10.1007/s11042-021-10594-9},
	doi = {10.1007/s11042-021-10594-9},
	abstract = {Image segmentation is an essential phase of computer vision in which useful information is extracted from an image that can range from finding objects while moving across a room to detect abnormalities in a medical image. As image pixels are generally unlabelled, the commonly used approach for the same is clustering. This paper reviews various existing clustering based image segmentation methods. Two main clustering methods have been surveyed, namely hierarchical and partitional based clustering methods. As partitional clustering is computationally better, further study is done in the perspective of methods belonging to this class. Further, literature bifurcates the partitional based clustering methods into three categories, namely K-means based methods, histogram-based methods, and meta-heuristic based methods. The survey of various performance parameters for the quantitative evaluation of segmentation results is also included. Further, the publicly available benchmark datasets for image-segmentation are briefed.},
	language = {en},
	urldate = {2022-04-26},
	journal = {Multimedia Tools and Applications},
	author = {Mittal, Himanshu and Pandey, Avinash Chandra and Saraswat, Mukesh and Kumar, Sumit and Pal, Raju and Modwel, Garv},
	month = feb,
	year = {2021},
	file = {Mittal et al. - 2021 - A comprehensive survey of image segmentation clus.pdf:/Users/lchris/Zotero/storage/E2C2JD4K/Mittal et al. - 2021 - A comprehensive survey of image segmentation clus.pdf:application/pdf},
}
@misc{Lavrenko2014,
	title = {Clustering 9: image representation},
	shorttitle = {Clustering 9},
	url = {https://www.youtube.com/watch?v=yDi2uX5tihc},
	abstract = {Full lecture: http://bit.ly/K-means 
Clustering can be used to represent natural images for the purpose of object detection or image tagging. We partition an image using a rectangular grid, compute a feature vector for each cell, and use K-means to assign each vector to a cluster. The clusters can then be used as discrete attributes for representing the entire image (this is known as a bag-of-visual-terms representation).},
	urldate = {2022-04-29},
	author = {{Victor Lavrenko}},
	month = jan,
	year = {2014},
}
@misc{Khandelwal2018,
	title = {Convolutional {Neural} {Network}({CNN}) {Simplified}},
	url = {https://medium.datadriveninvestor.com/convolutional-neural-network-cnn-simplified-ecafd4ee52c5},
	abstract = {Interested in understanding how some of the apps today classify images of your family and friends and have basics of machine learning then…},
	language = {en},
	urldate = {2022-04-29},
	journal = {Medium},
	author = {Khandelwal, Renu},
	month = oct,
	year = {2018},
	file = {Snapshot:/Users/lchris/Zotero/storage/FHY9E52P/convolutional-neural-network-cnn-simplified-ecafd4ee52c5.html:text/html},
}
@misc{Arc2018,
	title = {Convolutional {Neural} {Network}},
	url = {https://towardsdatascience.com/convolutional-neural-network-17fb77e76c05},
	abstract = {In this article, we will see what are Convolutional Neural Networks, ConvNets in short. ConvNets are the superheroes that took working…},
	language = {en},
	urldate = {2022-04-29},
	journal = {Medium},
	author = {Arc},
	month = dec,
	year = {2018},
	file = {Snapshot:/Users/lchris/Zotero/storage/7CIA8G34/convolutional-neural-network-17fb77e76c05.html:text/html},
}
@misc{Jordan2018,
	title = {Evaluating image segmentation models.},
	url = {https://www.jeremyjordan.me/evaluating-image-segmentation-models/},
	abstract = {When evaluating a standard machine learning model, we usually classify our predictions into four categories: true positives, false positives, true negatives, and false negatives. However, for the dense prediction task of image segmentation, it's not immediately clear what counts as a \&quot;true positive\&quot; and, more generally, how we},
	language = {en},
	urldate = {2022-04-29},
	journal = {Jeremy Jordan},
	month = may,
	year = {2018},
	file = {Snapshot:/Users/lchris/Zotero/storage/3NHAXKEH/evaluating-image-segmentation-models.html:text/html},
}
@article{Zhang2019,
	title = {A {Robust} {Bias}-{Correction} {Fuzzy} {Weighted} {C}-{Ordered}-{Means} {Clustering} {Algorithm}},
	volume = {2019},
	issn = {1024-123X},
	url = {https://www.hindawi.com/journals/mpe/2019/5984649/},
	doi = {10.1155/2019/5984649},
	abstract = {This paper proposes a modified fuzzy C-means (FCM) algorithm, which combines the local spatial information and the typicality of pixel data in a new fuzzy way. This new algorithm is called bias-correction fuzzy weighted C-ordered-means (BFWCOM) clustering algorithm. It can overcome the shortcomings of the existing FCM algorithm and improve clustering performance. The primary task of BFWCOM is the use of fuzzy local similarity measures (space and grayscale). Meanwhile, this new algorithm adds a typical analysis of data attributes to membership, in order to ensure noise insensitivity and the preservation of image details. Secondly, the local convergence of the proposed algorithm is mathematically proved, providing a theoretical preparation for fuzzy classification. Finally, data classification and real image experiments show the effectiveness of BFWCOM clustering algorithm, having a strong denoising and robust effect on noise images.},
	language = {en},
	urldate = {2022-04-29},
	journal = {Mathematical Problems in Engineering},
	author = {Zhang, Wenyuan and Huang, Tianyu and Chen, Jun},
	month = jun,
	year = {2019},
	note = {Publisher: Hindawi},
	pages = {e5984649},
	file = {Full Text PDF:/Users/lchris/Zotero/storage/YI3WIKIJ/Zhang et al. - 2019 - A Robust Bias-Correction Fuzzy Weighted C-Ordered-.pdf:application/pdf;Snapshot:/Users/lchris/Zotero/storage/KIJN89VY/5984649.html:text/html},
}
@article{Yu2020,
	title = {One {Algorithm} {May} {Not} {Fit} {All}: {How} {Selection} {Bias} {Affects} {Machine}                    {Learning} {Performance}},
	volume = {40},
	issn = {0271-5333},
	shorttitle = {One {Algorithm} {May} {Not} {Fit} {All}},
	url = {https://pubs.rsna.org/doi/full/10.1148/rg.2020200040},
	doi = {10.1148/rg.2020200040},
	abstract = {Machine learning (ML) algorithms have demonstrated high diagnostic accuracy in identifying and categorizing disease on radiologic images. Despite the results of initial research studies that report ML algorithm diagnostic accuracy similar to or exceeding that of radiologists, the results are less impressive when the algorithms are installed at new hospitals and are presented with new images. This phenomenon is potentially the result of selection bias in the data that were used to develop the ML algorithm. Selection bias has long been described by clinical epidemiologists as a key consideration when designing a clinical research study, but this concept has largely been unaddressed in the medical imaging ML literature. The authors discuss the importance of selection bias and its relevance to ML algorithm development to prepare the radiologist to critically evaluate ML literature for potential selection bias and understand how it might affect the applicability of ML algorithms in real clinical environments. ©RSNA, 2020},
	number = {7},
	urldate = {2022-04-06},
	journal = {RadioGraphics},
	author = {Yu, Alice                        C. and Eng, John},
	month = nov,
	year = {2020},
	note = {Publisher: Radiological Society of North America},
	pages = {1932--1937},
	file = {Full Text PDF:/Users/lchris/Zotero/storage/YMQSH2IR/Yu and Eng - 2020 - One Algorithm May Not Fit All How Selection Bias .pdf:application/pdf},
}
@misc{Warrick2020,
	title = {{YouTube}-{8M} {Dataset}},
	url = {https://medium.com/google-cloud/youtube-8m-dataset-c2ee9c79d136},
	abstract = {YouTube-8M is a project that was developed by Google AI/Research in 2016 to drive innovations and advancement in computer vision…},
	language = {en},
	urldate = {2022-04-16},
	journal = {Google Cloud - Community},
	author = {Warrick},
	month = may,
	year = {2020},
	file = {Snapshot:/Users/lchris/Zotero/storage/UM69XR6W/youtube-8m-dataset-c2ee9c79d136.html:text/html},
}
@misc{googleYT8M,
	title = {{YouTube}-{8M}: {A} {Large} and {Diverse} {Labeled} {Video} {Dataset} for {Video} {Understanding} {Research}},
	url = {https://research.google.com/youtube8m/},
	urldate = {2022-04-16},
	file = {YouTube-8M\: A Large and Diverse Labeled Video Dataset for Video Understanding Research:/Users/lchris/Zotero/storage/FPJ9NISZ/youtube8m.html:text/html},
}

@misc{HootSuite2022,
	title = {23 {YouTube} {Stats} {That} {Matter} to {Marketers} in 2022},
	url = {https://blog.hootsuite.com/youtube-stats-marketers/},
	abstract = {Here are the most important YouTube statistics marketers should know for 2022. Some of them are surprising!},
	language = {en-US},
	urldate = {2022-04-14},
	journal = {Social Media Marketing \& Management Dashboard},
	month = feb,
	year = {2022},
	file = {Snapshot:/Users/lchris/Zotero/storage/RE6DDTCL/youtube-stats-marketers.html:text/html},
}

@article{Stancic2022,
	title = {Classification {Efficiency} of {Pre}-{Trained} {Deep} {CNN} {Models} on {Camera} {Trap} {Images}},
	volume = {8},
	issn = {2313-433X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8879090/},
	doi = {10.3390/jimaging8020020},
	abstract = {This paper presents the evaluation of 36 convolutional neural network (CNN) models, which were trained on the same dataset (ImageNet). The aim of this research was to evaluate the performance of pre-trained models on the binary classification of images in a “real-world” application. The classification of wildlife images was the use case, in particular, those of the Eurasian lynx (lat. “Lynx lynx”), which were collected by camera traps in various locations in Croatia. The collected images varied greatly in terms of image quality, while the dataset itself was highly imbalanced in terms of the percentage of images that depicted lynxes.},
	number = {2},
	urldate = {2022-11-26},
	journal = {Journal of Imaging},
	author = {Stančić, Adam and Vyroubal, Vedran and Slijepčević, Vedran},
	month = jan,
	year = {2022},
	pmid = {35200723},
	pmcid = {PMC8879090},
	pages = {20},
	file = {PubMed Central Full Text PDF:/Users/lchris/Zotero/storage/LZU6YT6H/Stančić et al. - 2022 - Classification Efficiency of Pre-Trained Deep CNN .pdf:application/pdf},
}


@misc{GoogleSpeedGospel,
	title = {The {Google} {Gospel} of {Speed}},
	url = {https://www.thinkwithgoogle.com/future-of-marketing/digital-transformation/the-google-gospel-of-speed-urs-hoelzle/},
	abstract = {Google's search guru and SVP of Infrastructure, Urs Hoelzle, explains why speed is of the essence when it comes to search.},
	language = {en},
	urldate = {2022-12-13},
	journal = {Think with Google},
	file = {Snapshot:/Users/lchris/Zotero/storage/M3IRSKJZ/the-google-gospel-of-speed-urs-hoelzle.html:text/html},
}

@misc{WikipediaCurseDimension,
	title = {Curse of dimensionality},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Curse_of_dimensionality&oldid=1125139893},
	abstract = {The curse of dimensionality refers to various phenomena that arise when analyzing and organizing data in high-dimensional spaces that do not occur in low-dimensional settings such as the three-dimensional physical space of everyday experience.  The expression was coined by Richard E. Bellman when considering problems in dynamic programming.Dimensionally cursed phenomena occur in domains such as numerical analysis, sampling, combinatorics, machine learning, data mining and databases. The common theme of these problems is that when the dimensionality increases, the volume of the space increases so fast that the available data become sparse. In order to obtain a reliable result, the amount of data needed often grows exponentially with the dimensionality. Also, organizing and searching data often relies on detecting areas where objects form groups with similar properties; in high dimensional data, however, all objects appear to be sparse and dissimilar in many ways, which prevents common data organization strategies from being efficient.},
	language = {en},
	urldate = {2022-12-13},
	journal = {Wikipedia},
	month = dec,
	year = {2022},
	note = {Page Version ID: 1125139893},
	file = {Snapshot:/Users/lchris/Zotero/storage/Y9RVCRSW/Curse_of_dimensionality.html:text/html},
}

@misc{WikipediaFullText,
	title = {Full-text search},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Full-text_search&oldid=1121602001#False-positive_problem},
	abstract = {In text retrieval, full-text search refers to techniques for searching a single computer-stored document or a collection in a full-text database. Full-text search is distinguished from searches based on metadata or on parts of the original texts represented in databases (such as titles, abstracts, selected sections, or bibliographical references).
In a full-text search, a search engine examines all of the words in every stored document as it tries to match search criteria (for example, text specified by a user). Full-text-searching techniques became common in online bibliographic databases in the 1990s. Many websites and application programs (such as word processing software) provide full-text-search capabilities. Some web search engines, such as AltaVista, employ full-text-search techniques, while others index only a portion of the web pages examined by their indexing systems.},
	language = {en},
	urldate = {2022-12-03},
	journal = {Wikipedia},
	month = nov,
	year = {2022},
	note = {Page Version ID: 1121602001},
	file = {Snapshot:/Users/lchris/Zotero/storage/8QLRVKU8/Full-text_search.html:text/html},
}

@article{Beall2008,
	title = {The {Weaknesses} of {Full}-{Text} {Searching}},
	volume = {34},
	issn = {00991333},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0099133308001067},
	doi = {10.1016/j.acalib.2008.06.007},
	abstract = {Topics It's difficult to search successfully for documents on abstract topics in full-text databases. Subjects such as "health", "free will", and "ethics" generate large retrievals in Web search engines, decreasing the probability that the first few screens of search results will contain documents useful to the searcher. First-year university and college students, who are sometimes unable to narrow their searches, often encounter this problem in academic library databases.},
	language = {en},
	number = {5},
	urldate = {2022-12-03},
	journal = {The Journal of Academic Librarianship},
	author = {Beall, Jeffrey},
	month = sep,
	year = {2008},
	pages = {438--444},
	file = {Beall - 2008 - The Weaknesses of Full-Text Searching.pdf:/Users/lchris/Zotero/storage/WD5Q5843/Beall - 2008 - The Weaknesses of Full-Text Searching.pdf:application/pdf},
}


@inproceedings{Albawi2017,
	title = {Understanding of a convolutional neural network},
	doi = {10.1109/ICEngTechnol.2017.8308186},
	abstract = {The term Deep Learning or Deep Neural Network refers to Artificial Neural Networks (ANN) with multi layers. Over the last few decades, it has been considered to be one of the most powerful tools, and has become very popular in the literature as it is able to handle a huge amount of data. The interest in having deeper hidden layers has recently begun to surpass classical methods performance in different fields; especially in pattern recognition. One of the most popular deep neural networks is the Convolutional Neural Network (CNN). It take this name from mathematical linear operation between matrixes called convolution. CNN have multiple layers; including convolutional layer, non-linearity layer, pooling layer and fully-connected layer. The convolutional and fully-connected layers have parameters but pooling and non-linearity layers don't have parameters. The CNN has an excellent performance in machine learning problems. Specially the applications that deal with image data, such as largest image classification data set (Image Net), computer vision, and in natural language processing (NLP) and the results achieved were very amazing. In this paper we will explain and define all the elements and important issues related to CNN, and how these elements work. In addition, we will also state the parameters that effect CNN efficiency. This paper assumes that the readers have adequate knowledge about both machine learning and artificial neural network.},
	booktitle = {2017 {International} {Conference} on {Engineering} and {Technology} ({ICET})},
	author = {Albawi, Saad and Mohammed, Tareq Abed and Al-Zawi, Saad},
	month = aug,
	year = {2017},
	keywords = {Feature extraction, artificial neural networks, computer vision, Convolution, convolutional neural networks, Convolutional neural networks, deep learning, Image edge detection, Image recognition, machine learning, Neurons},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:/Users/lchris/Zotero/storage/YREBWTCT/8308186.html:text/html;IEEE Xplore Full Text PDF:/Users/lchris/Zotero/storage/LLL2BPYT/Albawi et al. - 2017 - Understanding of a convolutional neural network.pdf:application/pdf},
}

@article{Stancic2022,
	title = {Classification {Efficiency} of {Pre}-{Trained} {Deep} {CNN} {Models} on {Camera} {Trap} {Images}},
	volume = {8},
	issn = {2313-433X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8879090/},
	doi = {10.3390/jimaging8020020},
	abstract = {This paper presents the evaluation of 36 convolutional neural network (CNN) models, which were trained on the same dataset (ImageNet). The aim of this research was to evaluate the performance of pre-trained models on the binary classification of images in a “real-world” application. The classification of wildlife images was the use case, in particular, those of the Eurasian lynx (lat. “Lynx lynx”), which were collected by camera traps in various locations in Croatia. The collected images varied greatly in terms of image quality, while the dataset itself was highly imbalanced in terms of the percentage of images that depicted lynxes.},
	number = {2},
	urldate = {2022-11-26},
	journal = {Journal of Imaging},
	author = {Stančić, Adam and Vyroubal, Vedran and Slijepčević, Vedran},
	month = jan,
	year = {2022},
	pmid = {35200723},
	pmcid = {PMC8879090},
	pages = {20},
	file = {PubMed Central Full Text PDF:/Users/lchris/Zotero/storage/LZU6YT6H/Stančić et al. - 2022 - Classification Efficiency of Pre-Trained Deep CNN .pdf:application/pdf},
}

@misc{StackOverflow2016,
	type = {Forum post},
	title = {best way to preserve numpy arrays on disk},
	url = {https://stackoverflow.com/q/9619199},
	urldate = {2022-11-26},
	journal = {Stack Overflow},
	author = {CuriousMind},
	month = feb,
	year = {2016},
	file = {Snapshot:/Users/lchris/Zotero/storage/4L5D9HGV/best-way-to-preserve-numpy-arrays-on-disk.html:text/html},
}

@misc{noauthor_intuitive_2018,
	title = {An intuitive guide to {Convolutional} {Neural} {Networks}},
	url = {https://www.freecodecamp.org/news/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050/},
	abstract = {by Daphne Cornelisse An intuitive guide to Convolutional Neural Networks Photo by Daniel Hjalmarsson [https://unsplash.com/photos/41Wuv1xsmGM?utm\_source=unsplash\&utm\_medium=referral\&utm\_content=creditCopyText]  on Unsplash [https://unsplash.com/search/photos/brain?utm\_source=unsplash\&utm\_medium=referral\&utm\_content=creditCopyText] In this article, we will explore Convolutional Neural Networks (CNNs) and, on a high level, go through how they are inspired by the structure of the brain. If you wan},
	language = {en},
	urldate = {2022-11-26},
	journal = {freeCodeCamp.org},
	month = apr,
	year = {2018},
	file = {Snapshot:/Users/lchris/Zotero/storage/WG5YBRDX/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050.html:text/html},
}

@misc{Tolias2016,
	title = {Particular object retrieval with integral max-pooling of {CNN} activations},
	url = {http://arxiv.org/abs/1511.05879},
	doi = {10.48550/arXiv.1511.05879},
	abstract = {Recently, image representation built upon Convolutional Neural Network (CNN) has been shown to provide effective descriptors for image search, outperforming pre-CNN features as short-vector representations. Yet such models are not compatible with geometry-aware re-ranking methods and still outperformed, on some particular object retrieval benchmarks, by traditional image search systems relying on precise descriptor matching, geometric re-ranking, or query expansion. This work revisits both retrieval stages, namely initial search and re-ranking, by employing the same primitive information derived from the CNN. We build compact feature vectors that encode several image regions without the need to feed multiple inputs to the network. Furthermore, we extend integral images to handle max-pooling on convolutional layer activations, allowing us to efficiently localize matching objects. The resulting bounding box is finally used for image re-ranking. As a result, this paper significantly improves existing CNN-based recognition pipeline: We report for the first time results competing with traditional methods on the challenging Oxford5k and Paris6k datasets.},
	urldate = {2022-12-13},
	publisher = {arXiv},
	author = {Tolias, Giorgos and Sicre, Ronan and Jégou, Hervé},
	month = feb,
	year = {2016},
	note = {arXiv:1511.05879 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/lchris/Zotero/storage/6KJWQENE/Tolias et al. - 2016 - Particular object retrieval with integral max-pool.pdf:application/pdf;arXiv.org Snapshot:/Users/lchris/Zotero/storage/ZEE2LYQV/1511.html:text/html},
}

@misc{Gordo2016,
	title = {Deep {Image} {Retrieval}: {Learning} global representations for image search},
	shorttitle = {Deep {Image} {Retrieval}},
	url = {http://arxiv.org/abs/1604.01325},
	doi = {10.48550/arXiv.1604.01325},
	abstract = {We propose a novel approach for instance-level image retrieval. It produces a global and compact fixed-length representation for each image by aggregating many region-wise descriptors. In contrast to previous works employing pre-trained deep networks as a black box to produce features, our method leverages a deep architecture trained for the specific task of image retrieval. Our contribution is twofold: (i) we leverage a ranking framework to learn convolution and projection weights that are used to build the region features; and (ii) we employ a region proposal network to learn which regions should be pooled to form the final global descriptor. We show that using clean training data is key to the success of our approach. To that aim, we use a large scale but noisy landmark dataset and develop an automatic cleaning approach. The proposed architecture produces a global image representation in a single forward pass. Our approach significantly outperforms previous approaches based on global descriptors on standard datasets. It even surpasses most prior works based on costly local descriptor indexing and spatial verification. Additional material is available at www.xrce.xerox.com/Deep-Image-Retrieval.},
	urldate = {2022-12-13},
	publisher = {arXiv},
	author = {Gordo, Albert and Almazan, Jon and Revaud, Jerome and Larlus, Diane},
	month = jul,
	year = {2016},
	note = {arXiv:1604.01325 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: ECCV 2016 version + additional results},
	file = {arXiv Fulltext PDF:/Users/lchris/Zotero/storage/GG5AHLWQ/Gordo et al. - 2016 - Deep Image Retrieval Learning global representati.pdf:application/pdf;arXiv.org Snapshot:/Users/lchris/Zotero/storage/VD7IWVUS/1604.html:text/html},
}

@incollection{Goos2001,
	address = {Berlin, Heidelberg},
	title = {On the {Surprising} {Behavior} of {Distance} {Metrics} in {High} {Dimensional} {Space}},
	volume = {1973},
	isbn = {978-3-540-41456-8 978-3-540-44503-6},
	url = {http://link.springer.com/10.1007/3-540-44503-X_27},
	abstract = {In recent years, the eﬀect of the curse of high dimensionality has been studied in great detail on several problems such as clustering, nearest neighbor search, and indexing. In high dimensional space the data becomes sparse, and traditional indexing and algorithmic techniques fail from a eﬃciency and/or eﬀectiveness perspective. Recent research results show that in high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful. In this paper, we view the dimensionality curse from the point of view of the distance metrics which are used to measure the similarity between objects. We speciﬁcally examine the behavior of the commonly used Lk norm and show that the problem of meaningfulness in high dimensionality is sensitive to the value of k. For example, this means that the Manhattan distance metric (L1 norm) is consistently more preferable than the Euclidean distance metric (L2 norm) for high dimensional data mining applications. Using the intuition derived from our analysis, we introduce and examine a natural extension of the Lk norm to fractional distance metrics. We show that the fractional distance metric provides more meaningful results both from the theoretical and empirical perspective. The results show that fractional distance metrics can signiﬁcantly improve the eﬀectiveness of standard clustering algorithms such as the k-means algorithm.},
	language = {en},
	urldate = {2022-12-14},
	booktitle = {Database {Theory} — {ICDT} 2001},
	publisher = {Springer Berlin Heidelberg},
	author = {Aggarwal, Charu C. and Hinneburg, Alexander and Keim, Daniel A.},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Van den Bussche, Jan and Vianu, Victor},
	year = {2001},
	doi = {10.1007/3-540-44503-X_27},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {420--434},
	file = {Aggarwal et al. - 2001 - On the Surprising Behavior of Distance Metrics in .pdf:/Users/lchris/Zotero/storage/PDGSALVA/Aggarwal et al. - 2001 - On the Surprising Behavior of Distance Metrics in .pdf:application/pdf},
}

@misc{Bogdan2019,
	title = {Custom {Extended} {Sobel} {Filters}},
	url = {http://arxiv.org/abs/1910.00138},
	abstract = {Edge detection is widely and fundamental feature used in various algorithms in computer vision to determine the edges in an image. The edge detection algorithm is used to determine the edges in an image which are further used by various algorithms from line detection to machine learning that can determine objects based on their contour. Inspired by new convolution techniques in machine learning we discuss here the idea of extending the standard Sobel kernels, which are used to compute the gradient of an image in order to find its edges. We compare the result of our custom extended filters with the results of the standard Sobel filter and other edge detection filters using different image sets and algorithms. We present statistical results regarding the custom extended Sobel filters improvements.},
	urldate = {2022-12-14},
	publisher = {arXiv},
	author = {Bogdan, Victor and Bonchiş, Cosmin and Orhei, Ciprian},
	month = sep,
	year = {2019},
	note = {arXiv:1910.00138 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/lchris/Zotero/storage/UMB6C7LH/Bogdan et al. - 2019 - Custom Extended Sobel Filters.pdf:application/pdf;arXiv.org Snapshot:/Users/lchris/Zotero/storage/X6VR7QYF/1910.html:text/html},
}

@misc{noauthor_full-text_2022,
	title = {Full-text search},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Full-text_search&oldid=1121602001},
	abstract = {In text retrieval, full-text search refers to techniques for searching a single computer-stored document or a collection in a full-text database. Full-text search is distinguished from searches based on metadata or on parts of the original texts represented in databases (such as titles, abstracts, selected sections, or bibliographical references).
In a full-text search, a search engine examines all of the words in every stored document as it tries to match search criteria (for example, text specified by a user). Full-text-searching techniques became common in online bibliographic databases in the 1990s. Many websites and application programs (such as word processing software) provide full-text-search capabilities. Some web search engines, such as AltaVista, employ full-text-search techniques, while others index only a portion of the web pages examined by their indexing systems.},
	language = {en},
	urldate = {2022-12-14},
	journal = {Wikipedia},
	month = nov,
	year = {2022},
	note = {Page Version ID: 1121602001},
	file = {Snapshot:/Users/lchris/Zotero/storage/6FFQZNNW/Full-text_search.html:text/html},
}

@misc{noauthor_kernel_2022,
	title = {Kernel (image processing)},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Kernel_(image_processing)&oldid=1124968907},
	abstract = {In image processing, a kernel, convolution matrix, or mask is a small matrix used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between the kernel and an image.},
	language = {en},
	urldate = {2022-12-14},
	journal = {Wikipedia},
	month = dec,
	year = {2022},
	note = {Page Version ID: 1124968907},
	file = {Snapshot:/Users/lchris/Zotero/storage/LMRVWL5S/Kernel_(image_processing).html:text/html},
}

@misc{Dumoulin2018,
	title = {A guide to convolution arithmetic for deep learning},
	url = {http://arxiv.org/abs/1603.07285},
	abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
	urldate = {2022-12-14},
	publisher = {arXiv},
	author = {Dumoulin, Vincent and Visin, Francesco},
	month = jan,
	year = {2018},
	note = {arXiv:1603.07285 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/lchris/Zotero/storage/YZECYYY4/Dumoulin and Visin - 2018 - A guide to convolution arithmetic for deep learnin.pdf:application/pdf;arXiv.org Snapshot:/Users/lchris/Zotero/storage/NHHAXW82/1603.html:text/html},
}

@misc{Ren2016,
	title = {Faster {R}-{CNN}: {Towards} {Real}-{Time} {Object} {Detection} with {Region} {Proposal} {Networks}},
	shorttitle = {Faster {R}-{CNN}},
	url = {http://arxiv.org/abs/1506.01497},
	abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.},
	urldate = {2022-12-14},
	publisher = {arXiv},
	author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	month = jan,
	year = {2016},
	note = {arXiv:1506.01497 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Extended tech report},
	file = {arXiv Fulltext PDF:/Users/lchris/Zotero/storage/UN6H9ZFT/Ren et al. - 2016 - Faster R-CNN Towards Real-Time Object Detection w.pdf:application/pdf;arXiv.org Snapshot:/Users/lchris/Zotero/storage/I3KG63IX/1506.html:text/html},
}

@book{Ide2017,
	title = {Improvement of learning for {CNN} with {ReLU} activation by sparse regularization},
	abstract = {This paper introduces the sparse regularization forthe convolutional neural network (CNN) with the rectified linearunits (ReLU) in the hidden layers. By introducing the sparsenessfor the inputs of the ReLU, there is effect to push the inputs ofthe ReLU to zero in the learning process. Thus it is expectedthat the unnecessary increase of the outputs of the ReLU can beprevented. This is the similar effect with the Batch Normalization.Also the unnecessary negative values of the inputs of the ReLUcan be reduced by introducing the sparseness. This can improvethe generalization of the trained network. The relations betweenthe proposed approach and the Batch Normalization or themodifications of the activation function such as ExponentialLinear Unit (ELU) are also discussed. The effectiveness of the proposed method was confirmed through the detail experiments.},
	author = {Ide, Hidenori and Kurita, Takio},
	month = may,
	year = {2017},
	doi = {10.1109/IJCNN.2017.7966185},
	note = {Pages: 2691},
}
@misc{Swapna2020,
	title = {Convolutional {Neural} {Network} {\textbar} {Deep} {Learning}},
	url = {https://developersbreach.com/convolution-neural-network-deep-learning/},
	abstract = {CNN are very powerful and widely used in image classification, image recognition, computer vision etc and is deep learning neural network.},
	language = {en-US},
	urldate = {2022-12-14},
	journal = {Developers Breach},
	author = {{Swapna.}},
	month = aug,
	year = {2020},
	file = {Snapshot:/Users/lchris/Zotero/storage/VX4TSDYB/convolution-neural-network-deep-learning.html:text/html},
}
@article{Garcia2018,
	title = {Asymmetric {Spatio}-{Temporal} {Embeddings} for {Large}-{Scale} {Image}-to-{Video} {Retrieval}},
	abstract = {We address the problem of image-to-video retrieval. Given a query image, the aim is to identify the frame or scene within a collection of videos that best matches the visual input. Matching images to videos is an asymmetric task in which speciﬁc features for capturing the visual information in images and, at the same time, compacting the temporal correlation from videos are needed. Methods proposed so far are based on the temporal aggregation of hand-crafted features. In this work, we propose a deep learning architecture for learning speciﬁc asymmetric spatio-temporal embeddings for image-tovideo retrieval. Our method learns non-linear projections from training data for both images and videos and projects their visual content into a common latent space, where they can be easily compared with a standard similarity function. Experiments conducted here show that our proposed asymmetric spatio-temporal embeddings outperform stateof-the-art in standard image-to-video retrieval datasets.},
	language = {en},
	author = {Garcia, Noa},
	file = {Garcia - Asymmetric Spatio-Temporal Embeddings for Large-Sc.pdf:/Users/lchris/Zotero/storage/AYUMLBKV/Garcia - Asymmetric Spatio-Temporal Embeddings for Large-Sc.pdf:application/pdf},
}
@misc{Mowar2021,
	title = {Clickbait in {YouTube} {Prevention}, {Detection} and {Analysis} of the {Bait} using {Ensemble} {Learning}},
	url = {http://arxiv.org/abs/2112.08611},
	abstract = {Unscrupulous content creators on YouTube employ deceptive techniques such as spam and clickbait to reach a broad audience and trick users into clicking on their videos to increase their advertisement revenue. Clickbait detection on YouTube requires an in depth examination and analysis of the intricate relationship between the video content and video descriptors title and thumbnail. However, the current solutions are mostly centred around the study of video descriptors and other metadata such as likes, tags, comments, etc and fail to utilize the video content, both video and audio. Therefore, we introduce a novel model to detect clickbaits on YouTube that consider the relationship between video content and title or thumbnail. The proposed model consists of a stacking classifier framework composed of six base models (K Nearest Neighbours, Support Vector Machine, XGBoost, Naive Bayes, Logistic Regression, and Multilayer Perceptron) and a meta classifier. The developed clickbait detection model achieved a high accuracy of 92.89\% for the novel BollyBAIT dataset and 95.38\% for Misleading Video Dataset. Additionally, the stated classifier does not use meta features or other statistics dependent on user interaction with the video (the number of likes, followers, or comments) for classification, and thus, can be used to detect potential clickbait videos before they are uploaded, thereby preventing the nuisance of clickbaits altogether and improving the users streaming experience.},
	urldate = {2022-12-10},
	publisher = {arXiv},
	author = {Mowar, Peya and Jain, Mini and Goel, Ruchika and Vishwakarma, Dinesh Kumar},
	month = dec,
	year = {2021},
	note = {arXiv:2112.08611 [cs]},
	keywords = {Computer Science - Social and Information Networks},
	annote = {Comment: 26 pages, 16 figures},
	file = {arXiv Fulltext PDF:/Users/lchris/Zotero/storage/ZXLX43BU/Mowar et al. - 2021 - Clickbait in YouTube Prevention, Detection and Ana.pdf:application/pdf;arXiv.org Snapshot:/Users/lchris/Zotero/storage/3VRY865U/2112.html:text/html},
}
@article{Muller2001,
	title = {Performance {Evaluation} in {Content}-{Based} {Image} {Retrieval}: {Overview} and {Proposals}},
	shorttitle = {Performance {Evaluation} in {Content}-{Based} {Image} {Retrieval}},
	doi = {10.1016/S0167-8655(00)00118-5},
	abstract = {Evaluation of retrieval performance is a crucial problem in content-based image retrieval (CBIR). Many different methods for measuring the performance of a system have been created and used by researchers. This article discusses the advantages and shortcomings of the performance measures currently used. Problems such as defining a common image database for performance comparisons and a means of getting relevance judgments (or ground truth) for queries are explained. The relationship between CBIR and information retrieval (IR) is made clear, since IR researchers have decades of experience with the evaluation problem. Many of their solutions can be used for CBIR, despite the differences between the fields. Several methods used in text retrieval are explained. Proposals for performance measures and means of developing a standard test suite for CBIR, similar to that used in IR at the annual Text REtrieval Conference (TREC), are presented.},
	journal = {Pattern Recognition Letters},
	author = {Müller, Henning and Müller, Wolfgang and Squire, David and Marchand-Maillet, Stephane and Pun, Thierry},
	month = apr,
	year = {2001},
	pages = {593--601},
	file = {Full Text PDF:/Users/lchris/Zotero/storage/QQIHCQ37/Müller et al. - 2001 - Performance Evaluation in Content-Based Image Retr.pdf:application/pdf},
}
@misc{EarthWeb2022,
	title = {How {Many} {Videos} {Are} on {YouTube} in 2022? - {EarthWeb}},
	shorttitle = {How {Many} {Videos} {Are} on {YouTube} in 2022?},
	url = {https://earthweb.com/how-many-videos-are-on-youtube/},
	abstract = {How many videos are on YouTube? Let's find out.},
	language = {en-US},
	urldate = {2022-12-10},
	month = jul,
	year = {2022},
	note = {Section: YouTube},
	file = {Snapshot:/Users/lchris/Zotero/storage/I8IETLDI/how-many-videos-are-on-youtube.html:text/html},
}